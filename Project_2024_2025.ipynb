{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OzjPtTXK3Xb",
        "outputId": "9092ffc0-bb61-4d61-b46d-7e63fce7f33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyriemann in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (0.8)\n",
            "Requirement already satisfied: numpy>=2.0.0 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from pyriemann) (2.2.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from pyriemann) (1.15.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from pyriemann) (1.6.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from pyriemann) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from pyriemann) (3.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from scikit-learn>=0.24->pyriemann) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from matplotlib->pyriemann) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from matplotlib->pyriemann) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from matplotlib->pyriemann) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from matplotlib->pyriemann) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pavel\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyriemann) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from matplotlib->pyriemann) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pavel\\anaconda3\\envs\\sfml\\lib\\site-packages (from matplotlib->pyriemann) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pavel\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->pyriemann) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\pavel\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->pyriemann) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyriemann\n",
        "import numpy as np\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "from pyriemann.estimation import Covariances\n",
        "from pyriemann.tangentspace import TangentSpace\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrd7f_c8LBFA"
      },
      "source": [
        "## Step 1 : Dataset preparation and augmentation through overlapping window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUVzBKjJLh46"
      },
      "source": [
        "### Handling of the guided gestures training/validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWuuSVP8Ls_B"
      },
      "source": [
        "#### Guided training/validation data loading, shape and size checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufl5xoxSL14V",
        "outputId": "b815b846-95d8-4f97-b07f-a7d3bac95bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 8, 230000) 9200000\n"
          ]
        }
      ],
      "source": [
        "# Data loading\n",
        "X_guided=np.load(r\"C:\\Users\\pavel\\OneDrive\\Documents\\BIG DATA 2024-2025\\Session2\\Statistical foundations of machine learning\\project\\F422 EMG project data\\guided\\guided_dataset_X.npy\")\n",
        "\n",
        "# Shape and size checking\n",
        "print(X_guided.shape, np.size(X_guided))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G-_Wzp5Mgx_"
      },
      "source": [
        "The dataset shows the records of 5 sessions, 8 electrodes for 230 0000 points of time. The dataset contains then 9 200 000 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueg_a1IsMm79"
      },
      "source": [
        "#### Guided training/validation data augmentation, shape and size checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDdxVHskMqBX",
        "outputId": "70e1b53d-b299-456c-d04e-6b415be0344e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 8, 1837, 500) 36740000\n"
          ]
        }
      ],
      "source": [
        "# Data segmentation, window size = 500, overlap=75%\n",
        "X_guided_augmented=sliding_window_view(X_guided, 500,axis=2)[:,:, ::125]\n",
        "\n",
        "# Shape and size checking\n",
        "print(X_guided_augmented.shape,np.size(X_guided_augmented))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwlZZ464MuVu"
      },
      "source": [
        "The augmented dataset shows the records of 5 sessions, 8 electrodes and 18737 intervals of time (with an overlap of 75%). Each interval of time contains records for 500 points of time. The dataset contains now 36 740 000 records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuRuSeYQM9MM",
        "outputId": "ad837e5b-ae47-497a-85ba-56cb1d84ebae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.993478260869565\n"
          ]
        }
      ],
      "source": [
        "# Ratio of augmented data size to original data\n",
        "print(np.size(X_guided_augmented)/np.size(X_guided))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MWadmPgM_et"
      },
      "source": [
        "The augmented dataset has a size of about 4 times with respect to the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkAoKHkcNFkz"
      },
      "source": [
        "### Handling of the guided gestures training/validation target (hand pose estimation) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYeOJJhHNX3B"
      },
      "source": [
        "#### Guided training/validation target data  loading, shape and size checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Jb3EvpSUNZ8e"
      },
      "outputs": [],
      "source": [
        "# Data loading\n",
        "Y_guided=np.load(r\"C:\\Users\\pavel\\OneDrive\\Documents\\BIG DATA 2024-2025\\Session2\\Statistical foundations of machine learning\\project\\F422 EMG project data\\guided\\guided_dataset_y.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELO_l_jLOO7A",
        "outputId": "b9a76847-44cd-49f9-e681-985ab1bdd773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 51, 230000) 58650000\n"
          ]
        }
      ],
      "source": [
        "# Shape and size checking\n",
        "print(Y_guided.shape, np.size(Y_guided))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFxQe7OCOUxJ"
      },
      "source": [
        "The dataset shows the records of 51 joint-angles for 5 sessions (5 predefined hand postures) and 230 0000 points of time. The dataset contains then 58 650 000 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItdvvDzhOdTE"
      },
      "source": [
        "#### Guided training/validation target data segmentation, keeping of the up bound point of time of each window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZnjPeTuOfki",
        "outputId": "bfb092bb-cd09-46ad-f9b9-334a686e8dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 51, 1837, 500)\n"
          ]
        }
      ],
      "source": [
        "# Data segmentation, window size = 500, overlap=75%\n",
        "Y_guided_slided=sliding_window_view(Y_guided, 500,axis=2)[:,:, ::125]\n",
        "# Shape checking\n",
        "print(Y_guided_slided.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "F-Ww5kWtOmkH"
      },
      "outputs": [],
      "source": [
        "# Reducing each window to the up bound point of time\n",
        "Y_guided_slided=Y_guided_slided[:,:,:,-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuO34zq9OpQy",
        "outputId": "e056dcc1-b263-4edc-c4a9-37591f0474e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 51, 1837, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shape checking\n",
        "print(Y_guided_slided.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXShv4tbOv6B"
      },
      "source": [
        "### Handling of the free gestures training/validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqYv3zokO2FF"
      },
      "source": [
        "#### Free moves training/validation data loading, shape and size checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBiwUW0yO3__",
        "outputId": "3ea51327-8f6c-4b63-b98d-13f0f5b185c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 8, 270000) 10800000\n"
          ]
        }
      ],
      "source": [
        "# Data loading\n",
        "X_freemoves=np.load(r\"C:\\Users\\pavel\\OneDrive\\Documents\\BIG DATA 2024-2025\\Session2\\Statistical foundations of machine learning\\project\\F422 EMG project data\\freemoves\\freemoves_dataset_X.npy\")\n",
        "\n",
        "# Shape and size checking\n",
        "print(X_freemoves.shape, np.size(X_freemoves))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMvuTb6FPL9e"
      },
      "source": [
        "The dataset shows the records of 5 sessions, 8 electrodes for 270 0000 points of time. The dataset contains then 10 800 000 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6l_cSAqPQbn"
      },
      "source": [
        "#### Free moves training/validation data augmentation, shape and size checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r8uiCKuPT1X",
        "outputId": "1a10a01b-c23e-40e8-dd35-027ba01f578f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 8, 2157, 500) 43140000\n"
          ]
        }
      ],
      "source": [
        "# Data segmentation, window size = 500, overlap=75%\n",
        "X_freemoves_augmented=sliding_window_view(X_freemoves, 500,axis=2)[:,:, ::125]\n",
        "\n",
        "# Shape and size checking\n",
        "print(X_freemoves_augmented.shape,np.size(X_freemoves_augmented))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0ePGbfkPXbh"
      },
      "source": [
        "The augmented dataset shows the records of 5 sessions, 8 electrodes and 2157 intervals of time (with an overlap of 75%). Each interval of time contains records for 500 points of time, resulting then in a number of 43 140 000 records for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEyXW62LPZfi",
        "outputId": "77664937-6631-4088-a5dc-2daa24d84836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.9944444444444445\n"
          ]
        }
      ],
      "source": [
        "# Ratio of augmented data size to original data\n",
        "print(np.size(X_freemoves_augmented)/np.size(X_freemoves))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unbEsV_PPc6j"
      },
      "source": [
        "The augmented dataset has a size of about 4 times with respect to the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynzWnSkyPi7N"
      },
      "source": [
        "### Handling of the free gestures training/validation target (hand pose estimation) data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjbufUbfPqve"
      },
      "source": [
        "#### Free moves training/validation target data  loading, shape and size checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QgPBpuvgPtMc"
      },
      "outputs": [],
      "source": [
        "# Data loading\n",
        "Y_freemoves=np.load(r\"C:\\Users\\pavel\\OneDrive\\Documents\\BIG DATA 2024-2025\\Session2\\Statistical foundations of machine learning\\project\\F422 EMG project data\\freemoves\\freemoves_dataset_y.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQbZ3NgJP8Zn",
        "outputId": "962d723e-f959-4e0f-b76f-881ab32bd828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 51, 270000) 68850000\n"
          ]
        }
      ],
      "source": [
        "# Shape and size checking\n",
        "print(Y_freemoves.shape, np.size(Y_freemoves))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRga5OV2P-og"
      },
      "source": [
        "The dataset shows the records of 51 joint-angles for 5 sessions (5 predefined hand postures) and 270 0000 points of time. The dataset contains then 68 850 000 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY9OUEFBQGNH"
      },
      "source": [
        "#### Free moves training/validation target data segmentation, keeping of the up bound point of time of each window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27Q8Wa7QHlK",
        "outputId": "b00653fb-8a9c-44c9-c574-cd7012ff4421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 51, 2157, 500)\n"
          ]
        }
      ],
      "source": [
        "# Data segmentation, window size = 500, overlap=75%\n",
        "Y_freemoves_slided=sliding_window_view(Y_freemoves, 500,axis=2)[:,:, ::125]\n",
        "# Shape checking\n",
        "print(Y_freemoves_slided.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0iHwxk0sQNRu"
      },
      "outputs": [],
      "source": [
        "# Reducing each window to the up bound point of time\n",
        "Y_freemoves_slided=Y_freemoves_slided[:,:,:,-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4EnGeORQOmX",
        "outputId": "b50edcd2-ac6f-48e5-ca4d-8b866f607ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 51, 2157, 1)\n"
          ]
        }
      ],
      "source": [
        "# Shape checking\n",
        "print(Y_freemoves_slided.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMfMxRv_CQTC"
      },
      "source": [
        "# 2) Determine and implement an adequate cross-validation strategy to validate your regression models, specifying how you organized your data partitions for training and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkH-r-qAISio"
      },
      "source": [
        " Step 1 — Window extraction with session labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "aQhdHYBwHzjR"
      },
      "outputs": [],
      "source": [
        "def create_overlapping_windows(X, y, window_size=500, overlap=0.75):\n",
        "    \"\"\"\n",
        "    Segments raw sEMG and joint-angle signals into overlapping windows.\n",
        "    Also records the session index for each window.\n",
        "\n",
        "    Parameters:\n",
        "        X (np.ndarray): shape (num_sessions, num_electrodes, num_timesteps)\n",
        "        y (np.ndarray): shape (num_sessions, num_joints, num_timesteps)\n",
        "        window_size (int): number of time points per window (default = 500)\n",
        "        overlap (float): fraction of overlap between consecutive windows (e.g. 0.75 for 75%)\n",
        "\n",
        "    Returns:\n",
        "        X_windows (np.ndarray): shape (n_windows, num_electrodes, window_size)\n",
        "        y_windows (np.ndarray): shape (n_windows, num_joints, window_size)\n",
        "        session_labels (np.ndarray): shape (n_windows,), session index for each window\n",
        "    \"\"\"\n",
        "    step_size = int(window_size * (1 - overlap))  # Distance between window starts\n",
        "    X_windows, y_windows, session_labels = [], [], []\n",
        "\n",
        "    for session_idx in range(X.shape[0]):\n",
        "        emg = X[session_idx]     # shape (8, T)\n",
        "        joints = y[session_idx]  # shape (51, T)\n",
        "        T = emg.shape[1]\n",
        "\n",
        "        # Slide window over time axis\n",
        "        for start in range(0, T - window_size + 1, step_size):\n",
        "            end = start + window_size\n",
        "            X_windows.append(emg[:, start:end])        # Extract EMG window\n",
        "            y_windows.append(joints[:, start:end])     # Extract joint-angle window\n",
        "            session_labels.append(session_idx)         # Label the window by session\n",
        "\n",
        "    return np.array(X_windows), np.array(y_windows), np.array(session_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeZzU30sKWgw"
      },
      "source": [
        "Step 2 -  Leave-One-Session-Out Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "uwdiAa8ZIeVe"
      },
      "outputs": [],
      "source": [
        "def leave_one_session_out_cv(X_windows, y_windows, session_labels):\n",
        "    \"\"\"\n",
        "    Yields train/validation splits for Leave-One-Session-Out cross-validation.\n",
        "\n",
        "    Parameters:\n",
        "        X_windows (np.ndarray): EMG data windows\n",
        "        y_windows (np.ndarray): joint-angle windows\n",
        "        session_labels (np.ndarray): session index for each window\n",
        "\n",
        "    Yields:\n",
        "        X_train, X_val, y_train, y_val (each np.ndarray)\n",
        "    \"\"\"\n",
        "    unique_sessions = np.unique(session_labels)  # Usually [0, 1, 2, 3, 4]\n",
        "\n",
        "    for test_session in unique_sessions:\n",
        "        val_idx = np.where(session_labels == test_session)[0]    # Indices for validation\n",
        "        train_idx = np.where(session_labels != test_session)[0]  # Indices for training\n",
        "\n",
        "        X_train, X_val = X_windows[train_idx], X_windows[val_idx]\n",
        "        y_train, y_val = y_windows[train_idx], y_windows[val_idx]\n",
        "\n",
        "        yield X_train, X_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUIAKW1gKkxI"
      },
      "source": [
        "Step 3: Apply to Guided Gestures Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYzI7nMlIwMQ",
        "outputId": "074a7b8d-4584-4176-b4f0-0e6eb1571839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Guided Fold 1] Train shape: (7348, 8, 500), Validation shape: (1837, 8, 500)\n",
            "[Guided Fold 2] Train shape: (7348, 8, 500), Validation shape: (1837, 8, 500)\n",
            "[Guided Fold 3] Train shape: (7348, 8, 500), Validation shape: (1837, 8, 500)\n",
            "[Guided Fold 4] Train shape: (7348, 8, 500), Validation shape: (1837, 8, 500)\n",
            "[Guided Fold 5] Train shape: (7348, 8, 500), Validation shape: (1837, 8, 500)\n"
          ]
        }
      ],
      "source": [
        "# Segment windows and get session labels\n",
        "guided_X_win, guided_y_win, guided_labels = create_overlapping_windows(X_guided, Y_guided)\n",
        "\n",
        "# Run LOSO-CV\n",
        "for fold, (X_tr, X_val, y_tr, y_val) in enumerate(\n",
        "    leave_one_session_out_cv(guided_X_win, guided_y_win, guided_labels)\n",
        "):\n",
        "    print(f\"[Guided Fold {fold+1}] Train shape: {X_tr.shape}, Validation shape: {X_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Ce5w-GOvKv"
      },
      "source": [
        "Step 4: Apply to Free Gestures Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy2Xp2YsLNwH",
        "outputId": "4ca88dcf-bad4-45f5-db7f-71f46a24512b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Free Fold 1] Train shape: (8628, 8, 500), Validation shape: (2157, 8, 500)\n",
            "[Free Fold 2] Train shape: (8628, 8, 500), Validation shape: (2157, 8, 500)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Free Fold 3] Train shape: (8628, 8, 500), Validation shape: (2157, 8, 500)\n",
            "[Free Fold 4] Train shape: (8628, 8, 500), Validation shape: (2157, 8, 500)\n",
            "[Free Fold 5] Train shape: (8628, 8, 500), Validation shape: (2157, 8, 500)\n"
          ]
        }
      ],
      "source": [
        "# Segment windows and get session labels\n",
        "free_X_win, free_y_win, free_labels = create_overlapping_windows(X_freemoves, Y_freemoves)\n",
        "\n",
        "# Run LOSO-CV\n",
        "for fold, (X_tr, X_val, y_tr, y_val) in enumerate(\n",
        "    leave_one_session_out_cv(free_X_win, free_y_win, free_labels)\n",
        "):\n",
        "    print(f\"[Free Fold {fold+1}] Train shape: {X_tr.shape}, Validation shape: {X_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx-ZXpszPA5i"
      },
      "source": [
        "We apply Leave-One-Session-Out Cross-Validation separately to both the guided and free gesture datasets. This ensures that training and validation sets are fully separated in time, avoiding any overlap-induced leakage. Each validation set consists of data from a completely unseen recording session, providing a fair and realistic estimate of the model’s generalization performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sfml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
